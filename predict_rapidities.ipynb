{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from IPython.display import SVG\n",
    "import IPython\n",
    "\n",
    "import keras\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.utils.vis_utils import plot_model, model_to_dot\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import RMSprop\n",
    "\n",
    "import lieb_liniger_state as lls\n",
    "\n",
    "np.random.seed(7)\n",
    "\n",
    "# Necessary since otherwise we can't compare the accuracy between naive and ML initial guesses.\n",
    "keras.backend.set_floatx('float64')\n",
    "\n",
    "plt.rc('text', usetex=True)\n",
    "plt.rc('font', family='serif')\n",
    "\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "def measure_with_error(data, method):\n",
    "    measure = f\"{data.mean():.2f}\"\n",
    "    error = f\"{data.std():.2f}\"\n",
    "    error = error.lstrip(\"0.\")\n",
    "    print(f\"{method}: {measure}({error})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_of_particles = 10\n",
    "no_of_states = 20000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_state = lls.lieb_liniger_state(1, no_of_particles, no_of_particles)\n",
    "Is = np.zeros((no_of_states, no_of_particles))\n",
    "lambdas = np.zeros((no_of_states, no_of_particles))\n",
    "for i in range(no_of_states):\n",
    "    if i % 1000 == 0:\n",
    "        print(f\"Generated {i}/{no_of_states} states\")\n",
    "    bethe_numbers = lls.generate_bethe_numbers(no_of_particles, ground_state.Is)\n",
    "    llstate = lls.lieb_liniger_state(1, no_of_particles, no_of_particles, bethe_numbers)\n",
    "    llstate.lambdas = 2 * np.pi / llstate.L * llstate.Is\n",
    "    no_of_iterations = llstate.calculate_rapidities_newton()\n",
    "    Is[i] = bethe_numbers\n",
    "    lambdas[i] = llstate.lambdas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neural_net(no_of_particles):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units=no_of_particles**2, kernel_initializer='lecun_uniform', activation='tanh', input_dim=no_of_particles))\n",
    "    model.add(Dense(units=no_of_particles**2, kernel_initializer='lecun_uniform', activation='tanh'))\n",
    "    model.add(Dense(units=no_of_particles, kernel_initializer='lecun_uniform'))\n",
    "    model.compile(loss='mse', optimizer=RMSprop())\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "epochs=100\n",
    "model = neural_net(no_of_particles)\n",
    "keras.utils.plot_model(model, to_file='test_keras_plot_model.png', show_shapes=True)\n",
    "# IPython.display.Image('test_keras_plot_model.png')\n",
    "\n",
    "history = model.fit(x=Is, y=lambdas, epochs=epochs, verbose=1, validation_split=0.05) \n",
    "#                     callbacks=[EarlyStopping(monitor='val_loss', min_delta=0.0002, patience=5, verbose=1, mode='auto')]\n",
    "#                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"ticks\")\n",
    "plt.plot(range(1, len(history.history[\"val_loss\"]) + 1), history.history[\"val_loss\"])\n",
    "sns.despine()\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Validation error\")\n",
    "plt.title(r\"$N={0}$\".format(no_of_particles))\n",
    "plt.savefig(f\"val_loss_history_{no_of_particles}.pdf\", bbox='tight')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "sns.set_style(\"ticks\")\n",
    "ax.plot(Is[0], model.predict(Is[0].reshape(1, -1), batch_size=1)[0], \"ro\", label=\"Predicted\")\n",
    "ax.plot(Is[0], lambdas[0], \"bo\", label=\"Exact\")\n",
    "ax.set_xlabel(\"Bethe number\")\n",
    "ax.set_ylabel(\"Rapidity\")\n",
    "ax.set_title(r\"$N={0}$\".format(no_of_particles))\n",
    "ax.legend()\n",
    "sns.despine()\n",
    "fig.savefig(f\"rapidities_{no_of_particles}.pdf\", bbox='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "nstates = 1000\n",
    "\n",
    "dp = pd.DataFrame(data=np.zeros(shape=(8000, 3)), columns=[\"Iterations\", \"Method\", \"Damped\"])\n",
    "\n",
    "for k in range(nstates):\n",
    "    bethe_numbers = lls.generate_bethe_numbers(no_of_particles, ground_state.Is)\n",
    "\n",
    "    # Naive Bethe (damped)\n",
    "    llstate = lls.lieb_liniger_state(1, no_of_particles, no_of_particles, bethe_numbers)\n",
    "    llstate.lambdas = 2 * np.pi / llstate.L * llstate.Is\n",
    "    no_of_iterations = llstate.calculate_rapidities_newton(enable_damping=True, printing=False)\n",
    "    dp.iloc[k] = [no_of_iterations, \"Naive Bethe\", True]\n",
    "    \n",
    "    # Naive Bethe (undamped)\n",
    "    llstate = lls.lieb_liniger_state(1, no_of_particles, no_of_particles, bethe_numbers)\n",
    "    llstate.lambdas = 2 * np.pi / llstate.L * llstate.Is\n",
    "    no_of_iterations = llstate.calculate_rapidities_newton(enable_damping=False, printing=False)\n",
    "    dp.iloc[k+nstates] = [no_of_iterations, \"Naive Bethe\", False]\n",
    "\n",
    "    # Machine learning (damped)\n",
    "    llstate = lls.lieb_liniger_state(1, no_of_particles, no_of_particles, bethe_numbers)\n",
    "    llstate.lambdas = model.predict(bethe_numbers.reshape(1, -1), batch_size=1)[0]\n",
    "    no_of_iterations = llstate.calculate_rapidities_newton(enable_damping=True, printing=False)\n",
    "    dp.iloc[k+2*nstates] = [no_of_iterations, \"ML\", True]\n",
    "    \n",
    "    # Machine learning (undamped)\n",
    "    llstate = lls.lieb_liniger_state(1, no_of_particles, no_of_particles, bethe_numbers)\n",
    "    llstate.lambdas = model.predict(bethe_numbers.reshape(1, -1), batch_size=1)[0]\n",
    "    no_of_iterations = llstate.calculate_rapidities_newton(enable_damping=False, printing=False)\n",
    "    dp.iloc[k+3*nstates] = [no_of_iterations, \"ML\", False]\n",
    "\n",
    "    # Random (damped)\n",
    "    llstate = lls.lieb_liniger_state(1, no_of_particles, no_of_particles, bethe_numbers)\n",
    "    llstate.lambdas = np.random.normal(0, no_of_particles, no_of_particles)\n",
    "    no_of_iterations = llstate.calculate_rapidities_newton(enable_damping=True, printing=False)\n",
    "    dp.iloc[k+4*nstates] = [no_of_iterations, \"Random\", True]\n",
    "    \n",
    "    # Random (undamped)\n",
    "    llstate = lls.lieb_liniger_state(1, no_of_particles, no_of_particles, bethe_numbers)\n",
    "    llstate.lambdas = np.random.normal(0, no_of_particles, no_of_particles)\n",
    "    no_of_iterations = llstate.calculate_rapidities_newton(enable_damping=False, printing=False)\n",
    "    dp.iloc[k+5*nstates] = [no_of_iterations, \"Random\", False]\n",
    "\n",
    "    # Random sorted (damped)\n",
    "    llstate = lls.lieb_liniger_state(1, no_of_particles, no_of_particles, bethe_numbers)\n",
    "    llstate.lambdas = np.sort(np.random.normal(0, no_of_particles, no_of_particles))\n",
    "    no_of_iterations = llstate.calculate_rapidities_newton(enable_damping=True, printing=False)\n",
    "    dp.iloc[k+6*nstates] = [no_of_iterations, \"Random sorted\", True]\n",
    "    \n",
    "    # Random sorted (undamped)\n",
    "    llstate = lls.lieb_liniger_state(1, no_of_particles, no_of_particles, bethe_numbers)\n",
    "    llstate.lambdas = np.sort(np.random.normal(0, no_of_particles, no_of_particles))\n",
    "    no_of_iterations = llstate.calculate_rapidities_newton(enable_damping=False, printing=False)\n",
    "    dp.iloc[k+7*nstates] = [no_of_iterations, \"Random sorted\", False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"ticks\")\n",
    "ax = sns.barplot(x=\"Method\", y=\"Iterations\", hue=\"Damped\", data=dp, ci=\"sd\")\n",
    "ax.set_xlabel(\"\")\n",
    "ax.set_title(r\"$N={0}$\".format(no_of_particles))\n",
    "sns.despine()\n",
    "ax.get_figure().savefig(f\"iterations_{no_of_particles}.pdf\", bbox='tight')\n",
    "    \n",
    "\n",
    "measure_with_error(dp.loc[(dp['Method'] == \"Naive Bethe\") & dp['Damped']][\"Iterations\"], \"Naive Bethe (damped)\")\n",
    "measure_with_error(dp.loc[(dp['Method'] == \"Naive Bethe\") & ~dp['Damped']][\"Iterations\"], \"Naive Bethe (undamped)\")\n",
    "\n",
    "measure_with_error(dp.loc[(dp['Method'] == \"ML\") & dp['Damped']][\"Iterations\"], \"ML (damped)\")\n",
    "measure_with_error(dp.loc[(dp['Method'] == \"ML\") & ~dp['Damped']][\"Iterations\"], \"ML (undamped)\")\n",
    "\n",
    "measure_with_error(dp.loc[(dp['Method'] == \"Random\") & dp['Damped']][\"Iterations\"], \"Random (damped)\")\n",
    "measure_with_error(dp.loc[(dp['Method'] == \"Random\") & ~dp['Damped']][\"Iterations\"], \"Random (undamped)\")\n",
    "\n",
    "measure_with_error(dp.loc[(dp['Method'] == \"Random sorted\") & dp['Damped']][\"Iterations\"], \"Random sorted (damped)\")\n",
    "measure_with_error(dp.loc[(dp['Method'] == \"Random sorted\") & ~dp['Damped']][\"Iterations\"], \"Random sorted (undamped)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "times = pd.DataFrame(data=np.zeros(shape=(40, 3)), columns=[\"Times\", \"Method\", \"Damped\"])\n",
    "\n",
    "# Naive Bethe (undamped)\n",
    "for t in range(10):\n",
    "    start_time = time.time()\n",
    "    for k in range(1000):\n",
    "        bethe_numbers = lls.generate_bethe_numbers(no_of_particles, ground_state.Is)\n",
    "\n",
    "        llstate = lls.lieb_liniger_state(1, no_of_particles, no_of_particles, bethe_numbers)\n",
    "        llstate.lambdas = 2 * np.pi / llstate.L * llstate.Is\n",
    "        no_of_iterations = llstate.calculate_rapidities_newton(enable_damping=False, printing=False)\n",
    "    times.iloc[t] = [time.time() - start_time, \"Naive Bethe\", \"False\"]\n",
    "\n",
    "# Machine learning (undamped)\n",
    "for t in range(10):\n",
    "    start_time = time.time()\n",
    "    for k in range(1000):\n",
    "        bethe_numbers = lls.generate_bethe_numbers(no_of_particles, ground_state.Is)\n",
    "\n",
    "        llstate = lls.lieb_liniger_state(1, no_of_particles, no_of_particles, bethe_numbers)\n",
    "        llstate.lambdas = model.predict(bethe_numbers.reshape(1, -1), batch_size=1)[0]\n",
    "        no_of_iterations = llstate.calculate_rapidities_newton(enable_damping=False, printing=False)\n",
    "    times.iloc[t+10] = [time.time() - start_time, \"ML\", \"False\"]\n",
    "    \n",
    "# Random (undamped)\n",
    "for t in range(10):\n",
    "    start_time = time.time()\n",
    "    for k in range(1000):\n",
    "        bethe_numbers = lls.generate_bethe_numbers(no_of_particles, ground_state.Is)\n",
    "\n",
    "        llstate = lls.lieb_liniger_state(1, no_of_particles, no_of_particles, bethe_numbers)\n",
    "        llstate.lambdas = np.random.normal(0, no_of_particles, no_of_particles)\n",
    "        no_of_iterations = llstate.calculate_rapidities_newton(enable_damping=False, printing=False)\n",
    "    times.iloc[t+20] = [time.time() - start_time, \"Random\", \"False\"]\n",
    "    \n",
    "# Random sorted (undamped)\n",
    "for t in range(10):\n",
    "    start_time = time.time()\n",
    "    for k in range(1000):\n",
    "        bethe_numbers = lls.generate_bethe_numbers(no_of_particles, ground_state.Is)\n",
    "\n",
    "        llstate = lls.lieb_liniger_state(1, no_of_particles, no_of_particles, bethe_numbers)\n",
    "        llstate.lambdas = np.sort(np.random.normal(0, no_of_particles, no_of_particles))\n",
    "        no_of_iterations = llstate.calculate_rapidities_newton(enable_damping=False, printing=False)\n",
    "    times.iloc[t+30] = [time.time() - start_time, \"Random sorted\", \"False\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"ticks\")\n",
    "ax = sns.barplot(x=\"Method\", y=\"Times\", data=times, ci=\"sd\")\n",
    "ax.set_xlabel(\"\")\n",
    "ax.set_ylabel(\"Time (s)\")\n",
    "ax.set_title(r\"$N={0}$\".format(no_of_particles))\n",
    "sns.despine()\n",
    "ax.get_figure().savefig(f\"time_{no_of_particles}.pdf\", bbox='tight')\n",
    "\n",
    "measure_with_error(times.loc[(times['Method'] == \"Naive Bethe\")][\"Times\"], \"Naive Bethe\")\n",
    "measure_with_error(times.loc[(times['Method'] == \"ML\")][\"Times\"], \"ML\")\n",
    "measure_with_error(times.loc[(times['Method'] == \"Random\")][\"Times\"], \"Random\")\n",
    "measure_with_error(times.loc[(times['Method'] == \"Random sorted\")][\"Times\"], \"Random sorted\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
