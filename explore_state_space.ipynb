{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import pickle\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "import lieb_liniger_state as lls\n",
    "import rho_form_factor as rff\n",
    "from utils import map_to_entire_space, map_to_bethe_numbers\n",
    "import sum_rule\n",
    "\n",
    "np.random.seed(7)\n",
    "\n",
    "plt.rc('text', usetex=True)\n",
    "plt.rc('font', family='serif')\n",
    "\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = N = 5\n",
    "Imax = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_unique(state):\n",
    "    \"\"\"Check if all entries of a state are unique.\"\"\"\n",
    "    if len(state) > len(set(state)):\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "\n",
    "def generate_all_legal_new_states(current_state, previous_states, max_I):\n",
    "    \"\"\"\n",
    "    Generate all new legal states for the Lieb-Liniger model.\n",
    "\n",
    "    Legal states are all those states derived from the current state\n",
    "    that mutate one of the Bethe numbers by +/- 1, have only unique\n",
    "    entries, and have not previously been visited.\n",
    "    \"\"\"\n",
    "    legal_new_states = []\n",
    "    for i, bethe_number in enumerate(current_state):\n",
    "        for p in [-1, 1]:\n",
    "            new_state = sorted(list(current_state[:i]) + list(current_state[i+1:]) + list([current_state[i] + p]))\n",
    "            if all_unique(new_state) and new_state not in previous_states and not (np.abs(np.array(new_state)) > max_I).any():\n",
    "                legal_new_states.append(new_state)\n",
    "\n",
    "    return legal_new_states\n",
    "\n",
    "\n",
    "def descent_tree(root_state, max_no_of_descents=10):\n",
    "    already_explored = [root_state]\n",
    "    deltas = []\n",
    "    edges = [root_state]\n",
    "    unexpanded = [root_state]\n",
    "    no_edges = []\n",
    "    for k in range(100):\n",
    "        print(k)\n",
    "        no_edges.append(len(edges))\n",
    "\n",
    "        to_explore, delta = find_lowest_energy_delta(already_explored[-1], unexpanded)\n",
    "        deltas.append(delta)\n",
    "        already_explored.append(to_explore)\n",
    "        print(already_explored)\n",
    "        edges.remove(to_explore)\n",
    "        unexpanded.remove(to_explore)\n",
    "        descendants = generate_all_legal_new_states(to_explore, already_explored, Imax)\n",
    "        for k in descendants:\n",
    "            edges.append(k)\n",
    "            unexpanded.append(k)\n",
    "\n",
    "    print(\"plotting\")\n",
    "    plt.plot(range(100), no_edges)\n",
    "    plt.show()\n",
    "\n",
    "    return already_explored\n",
    "    \n",
    "def find_lowest_energy_delta(base, edges):\n",
    "    # print(\"start\")\n",
    "    # print(base)\n",
    "    energy_deltas = []\n",
    "    N = len(edges[0])\n",
    "    base_state = lls.lieb_liniger_state(1, L, N, base)\n",
    "    base_state.calculate_all()\n",
    "    base_energy  = base_state.energy\n",
    "    # print(\"base\", base_energy)\n",
    "    lowest_energy_diff = 10000000000\n",
    "    index = -1\n",
    "    for i, k in enumerate(edges):\n",
    "        state = lls.lieb_liniger_state(1, L, N, k)\n",
    "        state.calculate_all()\n",
    "        state_energy = state.energy\n",
    "        # print(\"state\", state_energy)\n",
    "        diff = state_energy - base_energy\n",
    "        # print(\"diff\", diff)\n",
    "        if diff < lowest_energy_diff:\n",
    "            # print(k)\n",
    "            lowest_energy_diff = diff\n",
    "            # print(lowest_energy_diff)\n",
    "            index = i\n",
    "    return edges[index], lowest_energy_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "state = lls.lieb_liniger_state(1, L, 10)\n",
    "already = descent_tree(list(state.Is), 1)\n",
    "print(already)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "added_data = []\n",
    "removed_data = []\n",
    "\n",
    "for k in range(10000):\n",
    "    if k % 100 == 0:\n",
    "        print(k)\n",
    "    rstate = lls.lieb_liniger_state(1, N, N, lls.generate_bethe_numbers(N, [], Imax))\n",
    "    orig_bethe_map = map_to_entire_space(rstate.Is, Imax)\n",
    "    rstate.calculate_all()\n",
    "    adjacent_states = generate_all_legal_new_states(rstate.Is, [], Imax)\n",
    "\n",
    "    ffs = {}\n",
    "    for k in adjacent_states:\n",
    "        lstate = lls.lieb_liniger_state(1, N, N, k)\n",
    "        lstate.calculate_all()\n",
    "        ff = rff.rho_form_factor(lstate, rstate)\n",
    "        ffs[np.abs(ff*ff)] = lstate.Is\n",
    "\n",
    "    removed_index = np.where(delta == -1)\n",
    "    added_index = np.where(delta == 1)\n",
    "    removed = np.zeros(2 * Imax + 1)\n",
    "    added = np.zeros(2 * Imax + 1)\n",
    "\n",
    "    np.put(removed, removed_index, 1)\n",
    "    np.put(added, added_index, 1)\n",
    "    \n",
    "    added_data.append({\"rstate\": orig_bethe_map, \"delta\": added})\n",
    "    removed_data.append({\"rstate\": orig_bethe_map, \"delta\": removed})\n",
    "\n",
    "with open('removed.pickle', 'wb') as f:\n",
    "    # Pickle the 'data' dictionary using the highest protocol available.\n",
    "    pickle.dump(removed_data, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "with open('added.pickle', 'wb') as f:\n",
    "    # Pickle the 'data' dictionary using the highest protocol available.\n",
    "    pickle.dump(added_data, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define baseline model\n",
    "def baseline_model(N):\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(N, input_dim=N, activation='relu'))\n",
    "    model.add(Dense(N, activation='relu'))\n",
    "    model.add(Dense(N, activation='relu'))\n",
    "    model.add(Dense(N**2, activation='softmax'))\n",
    "    # Compile model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "def get_allowed_prediction(probs, state):\n",
    "    \"\"\"Only give non-zero probabilities to allowed transitions.\"\"\"\n",
    "    for i, k in enumerate(state):\n",
    "        # Mask removals from unoccupied sites.\n",
    "        if k == 0:\n",
    "            for z in range(len(state)):\n",
    "                probs[i][z] = 0\n",
    "        # Mask additions to occupied sites.\n",
    "        if k == 1:\n",
    "            for z in range(len(state)):\n",
    "                probs[z][i] = 0\n",
    "    return probs / np.sum(probs)\n",
    "\n",
    "\n",
    "def mutate(model, state, history):\n",
    "    # print(\"Mutating\")\n",
    "    # print(state)\n",
    "    probs = get_allowed_prediction(model.predict(state.reshape(1, -1)).reshape(2 * Imax + 1, 2 * Imax + 1), state)\n",
    "    # print(\"probs\", probs)\n",
    "    sorted_probs = np.flipud(np.sort(probs.reshape(1, -1)[0]))\n",
    "    # print(sorted_probs)\n",
    "    for k in sorted_probs:\n",
    "        new_state = copy.copy(state)\n",
    "        # print(\"prob\", k)\n",
    "        pos = np.unravel_index(np.where(probs == k), (2 * Imax + 1, 2 * Imax + 1))\n",
    "        # print(pos[0], pos[1])\n",
    "        new_state[pos[1][0]] -= 1\n",
    "        new_state[pos[1][1]] += 1\n",
    "        # print(new_state)\n",
    "        if list(new_state) not in history:\n",
    "            return new_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_rem = pickle.load(open(\"removed.pickle\", \"rb\"))\n",
    "data_add = pickle.load(open(\"added.pickle\", \"rb\"))\n",
    "\n",
    "data = []\n",
    "for i, k in enumerate(data_rem):\n",
    "    data.append({\"rstate\": k[\"rstate\"], \"delta\": np.ravel(np.vstack((data_rem[i][\"delta\"] for _ in range(len(data_rem[i][\"delta\"])))) * np.vstack((data_add[i][\"delta\"] for _ in range(len(data_add[i][\"delta\"])))).T)})\n",
    "\n",
    "training_x = np.array([np.array(x[\"rstate\"]) for x in data[:8000]])\n",
    "training_y = np.array([x[\"delta\"] for x in data[:8000]])\n",
    "\n",
    "test_x = np.array([np.array(x[\"rstate\"]) for x in data[8000:]])\n",
    "test_y = np.array([x[\"delta\"] for x in data[8000:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate model with standardized dataset\n",
    "model = baseline_model(len(data[0][\"rstate\"]))\n",
    "model.fit(training_x, training_y, epochs=20, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.log(model.predict(test_x[1000].reshape(1, -1)).reshape(2 * Imax + 1, 2 * Imax + 1)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.log(model.predict(test_x[200].reshape(1, -1)).reshape(2 * Imax + 1, 2 * Imax + 1)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.vstack((np.array(test_x[200]), np.array(test_x[200]))))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsf_data = {}\n",
    "already_explored = []\n",
    "rstate = lls.lieb_liniger_state(1, L, N)\n",
    "rstate.calculate_all()\n",
    "current_state = map_to_entire_space(copy.copy(rstate.Is), Imax)\n",
    "ffactors = []\n",
    "for t in range(10000):\n",
    "    print(\"t\", t)\n",
    "#     print(current_state)\n",
    "    new_state = mutate(model, current_state, already_explored)\n",
    "#     print(\"new_state\", new_state)\n",
    "    already_explored.append(list(current_state))\n",
    "    lstate = lls.lieb_liniger_state(1, L, N, map_to_bethe_numbers(new_state, Imax))\n",
    "    lstate.calculate_all()\n",
    "    lstate.ff = rff.rho_form_factor(lstate, rstate)\n",
    "#     print(lstate.ff)\n",
    "\n",
    "    ffactors.append(lstate.ff)\n",
    "    integer_momentum = lstate.integer_momentum\n",
    "#     print(integer_momentum, lstate)\n",
    "    if integer_momentum in dsf_data.keys():\n",
    "        dsf_data[integer_momentum].append(lstate)\n",
    "    else:\n",
    "        dsf_data[integer_momentum] = [lstate]\n",
    "#     print(dsf_data[integer_momentum])\n",
    "    current_state = new_state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(dsf_data)\n",
    "print(\"sumrule\", sum_rule.compute_average_sumrule(dsf_data, rstate.energy, L, N, Imax, 2 * Imax + 1))\n",
    "# for z in dsf_data:\n",
    "#     print(z, data[z], len(data[z]))\n",
    "# print([map_to_bethe_numbers(k, 20) for k in already_explored])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.semilogy(np.abs(np.array(ffactors)), 'ro', markersize=1)\n",
    "plt.semilogy(np.sort(np.abs(np.array(ffactors)))[::-1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
